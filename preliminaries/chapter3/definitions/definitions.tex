\documentclass[../../../main]{subfiles}

\begin{document}

% subsection %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \subsection{Definitions}
 
 We begin with the following definition.
 
 \begin{defin}\label{ass-scheme-def}\index{association scheme}
  Let $X$ be a finite set of $v$ elements, and let $\RR=\{R_0, \dots, R_d\}$ be a collection of relations on $X$. We say that the ordered pair $\X=(X,\RR)$ is an {\it association scheme} with {\it $d$ classes} whenever the following are satisfied.
  \begin{defenum}
   \item $R_0=\{(x,x) : x \in X\}$;
   \item $R_i \cap R_j = \emptyset$ and $X \times X$ is the disjoint union of $R_0, \dots, R_d$;
   \item $R_i^t=R_{i'}$ for some $i' \in \{0, \dots, d\}$, where $R_i^t=\{(x,y) : (y,x) \in R_i\}$; and
   \item Given $(x,y) \in R_k$, the number of $z \in X$ such that $(x,z) \in R_i$ and $(z,y) \in R_j$ is a constant $p_{ij}^k$. We call the $p_{ij}^k$, the {\it intersection numbers}\index{intersection numbers} of the scheme.
  \end{defenum}
  The scheme $\X$ is {\it commutative} if
  \begin{defenum}[resume]
   \item $p_{ij}^k=p_{ji}^k$, for all $i,j,k \in \{0, \dots, d\}$.
  \end{defenum}
  The scheme is {\it symmetric} if
  \begin{defenum}[resume]
   \item $i=i'$, for every $i \in \{0, \dots, d\}$.
  \end{defenum}
  We denote $p_{ii}^0$ as $k_i$, the {\it valency} of the relation $R_i$.
 \end{defin}
 
 We present a few classical examples.
 
 \begin{ex}
 Let $G$ be a transitive permutation group on a set $X$, and let $\RR$ be the collection of orbits of $G$ on $X \times X$. Then $\X=(X,\RR)$ is an association scheme \cite[see][]{higman1,higman2}. In general $\X$ is non-commutative; however, the scheme is commutative if and only if the Hecke algebra is commutative \cite[see][]{wielandt}. $\X$ is symmetric if and only if the group is generously transitive\Cnote{sharp-trans}.
 \end{ex}
 
 \begin{ex}
  Recall The definition of a $q$-ary code. Let $\A$ be our $q$-ary alphabet, and take $X = \underbrace{\A \times \cdots \times \A}_n$. We partition $X \times X$ in the following way. We take $(x,y) \in R_i$ if and only if $\dist(x,y)=i$. Since the wreath product $S_q \wr S_n$ acts transitively on each $R_i$, we have that $\X=(X,\RR)$ is a symmetric association scheme on $n$ classes called the {\it Hamming scheme}\index{Hamming scheme}.
 \end{ex}
 
 \begin{ex}
  Let $V$ be a set of order $v$, and take $X=\binom{V}{k}$, where $k \leq v/2$. Partition $X \times X$ by $(x,y) \in R_i$ if and only if $\abs{x \cap y}=k-i$. The symmetric group $S_v$ acts transitively on each $R_i$, hence $\X=(X,\RR)$ is a symmetric association scheme of $k$ classes called the {\it Johnson scheme}\index{Johnson scheme}.
 \end{ex}
 
 Unless otherwise stated, we will assume that the association schemes we are working with are commutative. 
 
 \dinkus

 % subsection %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \subsection{Adjacency Algebras}
 
 The importance of association schemes resides in the following definition.
 
 \begin{defin}
  Let $\X=(X,\RR)$ be a $d$-class assocation scheme. For $i \in \{0, \dots, d\}$, define the $v \times v$ $(0,1)$-matrix $A_i$ with rows and columns indexed by elements of $X$ by $(A_i)_{xy} = 1$ if and only if $(x,y) \in R_i$. We call $A_i$ the {\it adjacency matrix} of the relation $R_i$. Then Definition \ref{ass-scheme-def} is equivalent to the following.
  \begin{defenum}
   \item\label{id-mat} $A_0=I$;
   \item\label{lin-indep} $A_0 + \cdots + A_d=J$;
   \item\label{trans-closed} $A_i^t=A_{i'}$ for some $i' \in \{0, \dots, d\}$; and
   \item\label{mult-closed} $A_iA_j=\sum_k p_{ij}^kA_k$, for every $i,j \in \{0, \dots d\}$.
  \end{defenum}
  If $\X$ is commutative, then
  \begin{defenum}[resume]
   \item\label{commutative-scheme} $A_iA_j=A_jA_i$, for each $i,j \in \{0, \dots, d\}$.
  \end{defenum}
  If $\X$ is symmetric, then
  \begin{defenum}[resume]
   \item\label{symmetric-scheme} $A_i^t=A_i$, for every $i \in \{0, \dots, d\}$.
  \end{defenum}
  By \ref{lin-indep}, the adjacency matrices of the scheme are $\C$-linearly independent and generate a subspace $\U$ of $\mat_v(\C)$ of dimension $d+1$. By \ref{mult-closed}, $\U$ is closed under standard matrix multiplication. We call $\U$ the {\it adjacency algebra}\index{adjacency algebra} of the association scheme $\X$.
  
  We further have that $A_i \circ A_j = \delta_{ij}A_i$. Therefore, $A_0, \dots, A_d$ also generate a commutative algebra $\hat \U$ with Schur multiplication for which they are primitive idempotents\Cnote{dual-scheme}. We therefore also call the adjacency matrices the {\it Schur idempotents}\index{Schur idempotents} of the scheme.
 \end{defin}
 
 Assume an ordering of $X=\{x_0, \dots, x_{v-1}\}$, and take $e_{x_i}$ to be the standard vector with $i$-th position equal to 1 and 0 elsewhere. Take $V$ to be the Hermitian space with the standard orthonormal basis $\{e_x : x \in X\}$. 
 
 Since we are assuming commutativity, the adjacency matrices $A_0, \dots, A_d$ are pairwise commuting, normal matrices. So, they share an eigenbasis, and by the Spectral Theorem for normal matrices, $V= \bigoplus_{i=1}^r V_i$, where the $V_i$ are maximal common eigenspaces. 
 
 Since $J=\sum_i A_i$, we find the eigenspace corresponding to the eigenvalue $v$ is spanned by $\jj_v$, i.e. it is 1-dimensional and hence maximal. It follows that this space is equal to $V_i$ for some $i$. We can assume, then, that $i=0$.
 
 If we take $E_i$ to be the orthogonal projection $V \rightarrow V_i$ with respect to the basis $\{e_x : x \in X\}$, then we can assume that $E_0=\abs{X}^{-1}J$, and we have $E_0 + \cdots + E_d = I$. Moreover, there is a unitary matrix $\Lambda$ such that $\Lambda^* E_i \Lambda = \diag(0,\dots,0,\underbrace{1,\dots,1}_{m_i},0,\dots,0)$, where we have used $m_i$ to denote $\ddim(V_i)$. The numbers $m_i$, for $i \in \{0, \dots, d\}$, are called the {\it multiplicities}\index{multiplicities} of the scheme.
 
 It can be shown \cite[see][Theorem 3.1]{bannaialgebraic} that the projection matrices $E_0, \dots, E_d$ are primitive idempotents of $\U$ and form a dual basis of $\U$. It follows that there are constants $P_{ij}$ and $Q_{ij}$, for $i,j \in \{0, \dots, d\}$, called the {\it eigenvalues}\index{eigenvalues of a scheme} and {\it dual-eigenvalues}\index{dual-eigenvalues of a scheme} of the scheme, such that $A_j=\sum_i P_{ij}E_i$ and $E_j=\abs{X}^{-1}\sum_i Q_{ij}A_i$. Using these constants, we form the matrices $P$ and $Q$ with $(i,j)$-th entry given by $P_{ij}$ and $Q_{ij}$, respectively, and we call these matrices the {\it first} and {\it second character tables}\index{character tables} of the scheme. By what has been said, we have at once that $PQ=QP=vI$.
 
 \begin{ex}
  Using the notation of the previous section, we see that a strongly regular graph has first and second character tables
  \begin{equation}
   \begin{pmatrix}
      1 & k & v-k-1 \\
      1 & r & -r-1 \\
      1 & s & -s-1
     \end{pmatrix},
   \frac{1}{r-s}\begin{pmatrix}
      r-s & -k-(v-1)s & k+(v-1)r \\
      r-s & v-k-s & k-v-r \\
      r-s & s-k & k-r
     \end{pmatrix},
  \end{equation}
  respectively.
 \end{ex}
 
 \dinkus
 
 % subsection %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \subsection{Parameters}
 
 As we have seen, there are numerous parameters related to a given assocation scheme. The regular structure of a scheme allows us to relate these parameters together in a number of interesting ways.
 
 To begin, we have a few immediate properties of the intersection numbers.
 
 \begin{prop}
  \begin{defenum}
   \item[]
   \item $p_{0j}^k=\delta_{jk}$,
   \item $p_{i0}^k=\delta_{ik}$,
   \item $p_{ij}^0=k_i\delta_{ij'}$,
   \item $p_{ij}^k=p_{i'j'}^{k'}$,
   \item $\sum_{j=0}^d p_{ij}^k=k_i$,
   \item $k_\gamma p_{\alpha\beta}^\gamma=k_\beta p_{\alpha'\gamma}^\beta=k_\alpha p_{\gamma\beta'}^\alpha$, and
   \item $\ssum_{\alpha=0}^d p_{ij}^\alpha p_{k\alpha}^\ell=\ssum_{\beta=0}^d p_{ki}^\beta p_{\beta j}^\ell$.
  \end{defenum}
 \end{prop}
 
 \begin{proof}
  (7.7.a-d) are a restatment of the definitions. To show (7.7.e), fix a pair $(x,y) \in R_k$ and count the points $z \in X$ such that $(x,z) \in R_i$. For (7.7.f), count the triangles $(x,y,z)$ such that $(x,y) \in R_\gamma$, $(x,z) \in R_\alpha$, and $(z,y) \in R_\beta$. Finally, we show (7.7.g) in the following way. Fix a pair $(x,y) \in R_\ell$ and count the pairs $(z,w)$ such that $(x,z) \in R_k$, $(z,w) \in R_i$, and $(w,y) \in R_j$.
 \end{proof}
 
 Regarding the bases, we have the following, where $\tau(C)=\sum_{i,j}C_{ij}$ is the sum of the elements of the matrix $C$.
 
 \begin{prop}
  \begin{defenum}
   \item[]
   \item $\tr(A_i)=\delta_{i0}|X|$,
   \item $\tau(A_i)=|X|k_i$,
   \item $\tr(E_i)=m_i$, and
   \item $\tau(E_i)=\delta_{i0}|X|$.
  \end{defenum}
 \end{prop}
 
 \begin{proof}
  Trivial.
 \end{proof}
 
 Regarding the character tables of the scheme, we have the following two propositions.
 
 \begin{prop}
  For each $i \in \{0, \dots, d\}$,
  \begin{defenum}
   \item\label{p-one} $P_{i0}=1$,
   \item\label{p-two} $P_{0i}=k_i$,
   \item\label{q-one} $Q_{i0}=1$, and
   \item\label{q-two} $Q_{0i}=m_i$.
  \end{defenum}
 \end{prop}
 
 \begin{proof}
  To show \ref{p-one}, compare coefficients in $\ssum_i E_i = A_0 = I = \ssum_i P_{i0}E_i$. To show \ref{p-two}, apply the functional $\tau$ to $A_i=\ssum_j P_{ji}E_j$. Comparing coefficients in $E_0=\abs{X}^{-1}J=\abs{X}^{-1}\ssum_i A_i$ yields \ref{q-one}. Finally, taking the trace of $E_i=\abs{X}^{-1}\ssum_j Q_{ji}A_j$ gives \ref{q-two}.
 \end{proof}
 
 \begin{prop}
  For each $i,j \in \{0, \dots, d\}$,
  \begin{defenum}
   \item\label{eigen-first} $Q_{ij}/m_j=\bar{P_{ij}}/k_i$,
   \item\label{first-orth-rel} $\ssum_{\nu=0}^d k_\nu^{-1}P_{i\nu}\bar{P_{j\nu}}=\delta_{ij}\abs{X}/m_i$, and
   \item\label{second-orth-rel} $\ssum_{\nu=0}^d m_\nu P_{\nu i}\bar{P_{\nu j}}=\delta_{ij}\abs{X}k_i$.
  \end{defenum}
  It is custumary to refer to \ref{first-orth-rel} and \ref{second-orth-rel} as the {\it first} and {\it second orthogonality relations of association schemes}\index{first and second orthogonality relations of schemes}.
 \end{prop}
 
 \begin{proof}
  To show \ref{eigen-first}, note that $E_j \circ A_i = \abs{X}^{-1}Q_{ij}A_i$; hence,
  \begin{align*}
   \tau(E_j \circ A_i) &= \tr(E_jA_i^t) \\
   &= \tr(E_jA_{i'}) \\
   &= \tr(P_{ji'}E_j) \\
   &= P_{ji'}m_j \\
   &= m_j\bar{P_{ji}}.
  \end{align*}
  Similarly, $\tau(\abs{X}^{-1}Q_{ij}A_i)=Q_{ij}k_i$. The remaining points follow by writing $PQ=\abs{X}I$ and $QP=\abs{X}$ entrywise.
 \end{proof}
 
 Much more can be said of this most intersting topic, but we do not have the space to pursue it here. It suffices to say that the character tables of a scheme in a sense characterize the scheme. In order to derive these character tables, however, we will often try to employ a further object, namely, the intersection matrices of the scheme.
 
 \dinkus
 
 % subsection %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \subsection{Intersection Matrices}
 
 If we regard left multiplication of $\U$ as linear transformations of $\U$ and express them in terms of the basis $\{A_0, \dots, A_d\}$, then we have an algebra homomorphism $\U \rightarrow \mat_v(\C)$ called the {\it left regular representation of $\U$} with respect to $\{A_0, \dots, A_d\}$. 
 
 For $i \in \{0, \dots, d\}$, define the matrix $B_i$ by $(B_i)_{jk}=p_{ij}^k$, called the {\it $i$-th intersection matrix}\index{intersection matrix}. It then follows by \ref{mult-closed} that the image of $A_i$ under the above homomorphism is $B_i^t$, whence $A_i \leftrightarrow B_i^t$ is an isomorphism. Since, however, we are assuming that our schemes are commutative, transposition is an isomorphism; thus, $A_i \leftrightarrow B_i$ is an isomorphism. If we denote $\BB=\sharps{B_0, \dots, B_d}$, then we have shown $\U\simeq\BB$.
 
 That the intersection matrices and the isomorphism given above are important for us is shown in the next result. First, however, we say that a vector is in {\it standard form}\index{standard form} if the first entry is 1.
 
 \begin{thm}\label{intersect-thm}
 Let $\X=(X,\RR)$ be a commutative association scheme with $d$ classes. Let $v_i=(P_{i0},\dots,P_{id})$ and $u_i=(\bar{P_{i0}}/k_0, \dots, \bar{P_{id}}/k_d)$ be the row vectors obtained by standardizing the first row and column of $P$ and $Q$, respectively. Then $u_i$ is the unique standardized common left eigenvector $u$ of the matrices $B_j$ such that $uB_j=P_{ij}u$. Similarly, $v_i^t$ is the common right eigenvector $v^t$ of the matrices $B_j$ such that $B_jv^t=P_{ij}v^t$.
 \end{thm}

 \begin{proof}
  We consider the left regular representation of the adjacency algebra $\U$ of $\X$. With respect to the basis $\{A_0, \dots, A_d\}$, the image of $A_j$ is $B_j^t$. With respect to the basis $\{E_0, \dots, E_d\}$, the image of $A_j$ is $\diag(P_{0j}, \dots, P_{dj})$. Since $E_jP=A_j$, we have that $B_j^t = P^{-1}\diag(P_{0j}, \dots, P_{dj})P$, hence $B_jP^t=P^t\diag(P_{0j}, \dots, P_{dj})$.  Thus, the $i$-th column $v_i^t$ of $P^t$ is a right eigenvector of $B_j$ belonging to the eigenvalue $P_{ij}$.
  
  Multiplying by $Q^t$ on the right and left, $Q^tB_j=\diag(P_{0j}, \dots, P_{dj})Q^t$. So, the $i$-th row vector $(Q_{0i}, \dots, Q_{di})$ of $Q^t$ is a left eigenvector of $B_j$ belonging to the eigenvalue $P_{ij}$. By \ref{eigen-first}, $m_i^{-1}(Q_{0i}, \dots, Q_{di})=u_i$.
  
  Let $u$ be a common left eigenvector of $B_j$ such that $uB_j=P_{ij}u$, for all $j$. By the linear independence of $\{u_k\}$, we can write $u=\ssum_k\lambda_ku_k$. Applying $B_j$, $P_{ij}\ssum_k\lambda_ku_k=\ssum_k\lambda_kP_{kj}u_k$, hence $\lambda_kP_{ij}=\lambda_kP_{kj}$, for every $j$. If $\lambda_k \neq 0$, then $P_{ij}=P_{kj}$ so that $i=k$ as $\ddet(P) \neq 0$. Therefore, $u$ is a multiple of $u_i$
  
  $v_i^t$ is similarly characterized.
 \end{proof}
 
 As stated in \cite{bannaialgebraic}, by virture of this result, one can conceivably derive the character tables $P$ and $Q$ from the intersection matrices. In particular, if the algebra $\BB$ is generated by a single $B_j$, we can use the single matrix $B_j$ to calculate the character tables. Following Lemma 2.2.1 of \cite{distance-regular-graphs}, the authors go on to point out that if some $B_j$ has $d+1$ distinct eigenvalues, then we can similarly use this intersection matrix. Of course, if $\BB$ is cyclic, then this property is satisfied by the generator matrix.

\end{document}
